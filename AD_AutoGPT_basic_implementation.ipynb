{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/elyase/geotext/archive/master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uWDbuuSoQqE",
        "outputId": "e935cc22-8240-40b5-f8fc-044432df8182"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/elyase/geotext/archive/master.zip\n",
            "  Using cached https://github.com/elyase/geotext/archive/master.zip\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Uninstall the current PyTorch installation\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "\n",
        "# Install PyTorch with CUDA support. Replace 'cu118' with your CUDA version if different.\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEkxiEQP8w0t",
        "outputId": "9b61232d-f39f-4ba5-bee4-71fa721f89d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.0+cu118\n",
            "Uninstalling torch-2.5.0+cu118:\n",
            "  Successfully uninstalled torch-2.5.0+cu118\n",
            "Found existing installation: torchvision 0.20.0+cu118\n",
            "Uninstalling torchvision-0.20.0+cu118:\n",
            "  Successfully uninstalled torchvision-0.20.0+cu118\n",
            "Found existing installation: torchaudio 2.5.0+cu118\n",
            "Uninstalling torchaudio-2.5.0+cu118:\n",
            "  Successfully uninstalled torchaudio-2.5.0+cu118\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.5.0%2Bcu118-cp310-cp310-linux_x86_64.whl (838.3 MB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.20.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.5.0+cu118 torchaudio-2.5.0+cu118 torchvision-0.20.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u-vy7JXQnfic",
        "outputId": "6a755a70-f679-4a01-856c-ba40d256a999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu118)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "/usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at6native12cpu_fallbackERKN3c1014OperatorHandleEPSt6vectorINS1_6IValueESaIS6_EEb",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-66b2f18864db>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load NVIDIA's Llama model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3825\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# We do not want to modify the config inplace in from_pretrained.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3826\u001b[0;31m         config = cls._autoset_attn_implementation(\n\u001b[0m\u001b[1;32m   3827\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_flash_attention_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_flash_attention_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_autoset_attn_implementation\u001b[0;34m(cls, config, use_flash_attention_2, torch_dtype, device_map, check_device_map)\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 \u001b[0mcheck_device_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_device_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m             )\n\u001b[0;32m-> 1563\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mrequested_attn_implementation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sdpa\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m             \u001b[0;31m# use_flash_attention_2 takes priority over SDPA, hence SDPA treated in this elif.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             config = cls._check_and_enable_sdpa(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mis_torch_xla_available\u001b[0;34m(check_is_tpu, check_is_gpu)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_is_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_XLAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at6native12cpu_fallbackERKN3c1014OperatorHandleEPSt6vectorINS1_6IValueESaIS6_EEb",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers torch beautifulsoup4 requests gensim geopandas matplotlib\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from geotext import GeoText\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from datetime import datetime\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load NVIDIA's Llama model and tokenizer\n",
        "model_name = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Initialize data structures to store news data\n",
        "saved_news = []\n",
        "summaries = []\n",
        "spatial_data = []\n",
        "temporal_data = []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_and_save_news():\n",
        "    print(\"Searching for the latest news articles about Alzheimerâ€™s disease...\")\n",
        "\n",
        "    # Multiple news URLs for Alzheimer's disease\n",
        "    urls = [\n",
        "        \"https://www.alz.org/news\",\n",
        "        \"https://www.mayoclinic.org/diseases-conditions/alzheimers-disease/news\",\n",
        "        \"https://www.bbc.com/news/topics/c52ew7kze47t/alzheimers-disease\",\n",
        "        \"https://www.nih.gov/news-events/news-releases/nih-funded-researchers-discover-new-insights-alzheimers-disease\"\n",
        "    ]\n",
        "\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                saved_news.append(url)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {url}: {e}\")\n",
        "\n",
        "    print(f\"Found {len(saved_news)} news URLs.\")\n",
        "    return saved_news\n",
        "\n",
        "# Example usage\n",
        "saved_news = search_and_save_news()\n",
        "print(saved_news)\n"
      ],
      "metadata": {
        "id": "3Mu8tKX9oZV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_news_content(url):\n",
        "    print(f\"Fetching content from {url}...\")\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    paragraphs = soup.find_all('p')\n",
        "    content = ' '.join([para.get_text() for para in paragraphs])\n",
        "    return content[:2000]  # Limit content for this example\n",
        "\n",
        "def call_nvidia_model(content):\n",
        "    print(\"Summarizing content using NVIDIA Llama-3.1-Nemotron-70B...\")\n",
        "\n",
        "    # Prepare prompt for the model\n",
        "    prompt = f\"Summarize the following article: {content}\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Tokenize the message for the NVIDIA model\n",
        "    tokenized_message = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
        "\n",
        "    # Generate response using the model\n",
        "    response_token_ids = model.generate(tokenized_message['input_ids'].cuda(),\n",
        "                                        attention_mask=tokenized_message['attention_mask'].cuda(),\n",
        "                                        max_new_tokens=512,\n",
        "                                        pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode the generated tokens to get the response\n",
        "    generated_tokens = response_token_ids[:, len(tokenized_message['input_ids'][0]):]\n",
        "    generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "    return generated_text\n",
        "\n",
        "def summarize_news():\n",
        "    for url in saved_news:\n",
        "        content = fetch_news_content(url)\n",
        "        summary = call_nvidia_model(content)\n",
        "        summaries.append(summary)\n",
        "    print(\"News articles summarized successfully.\")\n",
        "    return summaries\n",
        "\n",
        "# Example usage\n",
        "summaries = summarize_news()\n",
        "for i, summary in enumerate(summaries):\n",
        "    print(f\"Summary {i+1}:\\n{summary}\\n\")\n"
      ],
      "metadata": {
        "id": "UBB4A-SR_MWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_nvidia_model(content):\n",
        "    print(\"Summarizing content using NVIDIA Llama-3.1-Nemotron-70B on GPU...\")\n",
        "\n",
        "    # Prepare prompt for the model\n",
        "    prompt = f\"Summarize the following article: {content}\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Tokenize the message for the NVIDIA model\n",
        "    tokenized_message = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
        "\n",
        "    # Generate response using the model on GPU\n",
        "    response_token_ids = model.generate(tokenized_message['input_ids'].cuda(),\n",
        "                                        attention_mask=tokenized_message['attention_mask'].cuda(),\n",
        "                                        max_new_tokens=512,\n",
        "                                        pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode the generated tokens to get the response\n",
        "    generated_tokens = response_token_ids[:, len(tokenized_message['input_ids'][0]):]\n",
        "    generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "RtQz-Yoo79SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_news_content(url):\n",
        "    print(f\"Fetching content from {url}...\")\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    paragraphs = soup.find_all('p')\n",
        "    content = ' '.join([para.get_text() for para in paragraphs])\n",
        "    return content[:2000]  # Limit content for this example\n",
        "\n",
        "def call_nvidia_model(content):\n",
        "    print(\"Summarizing content using NVIDIA Llama-3.1-Nemotron-70B on GPU...\")\n",
        "\n",
        "    # Prepare prompt for the model\n",
        "    prompt = f\"Summarize the following article: {content}\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Tokenize the message for the NVIDIA model\n",
        "    tokenized_message = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
        "\n",
        "    # Move input tensors to GPU (CUDA)\n",
        "    input_ids = tokenized_message['input_ids'].cuda()\n",
        "    attention_mask = tokenized_message['attention_mask'].cuda()\n",
        "\n",
        "    # Generate response using the model on GPU\n",
        "    response_token_ids = model.generate(input_ids,\n",
        "                                        attention_mask=attention_mask,\n",
        "                                        max_new_tokens=512,\n",
        "                                        pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode the generated tokens to get the response\n",
        "    generated_tokens = response_token_ids[:, len(input_ids[0]):]\n",
        "    generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "\n",
        "def summarize_news():\n",
        "    for url in saved_news:\n",
        "        content = fetch_news_content(url)\n",
        "        summary = call_nvidia_model(content)\n",
        "        summaries.append(summary)\n",
        "    print(\"News articles summarized successfully.\")\n",
        "    return summaries\n",
        "\n",
        "# Example usage\n",
        "summaries = summarize_news()\n",
        "for i, summary in enumerate(summaries):\n",
        "    print(f\"Summary {i+1}:\\n{summary}\\n\")\n"
      ],
      "metadata": {
        "id": "kHkbB17H7uL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_spatiotemporal_data():\n",
        "    for summary in summaries:\n",
        "        # Simulate temporal extraction (use current date)\n",
        "        temp_date = datetime.now().strftime('%Y-%m-%d')\n",
        "        temporal_data.append(temp_date)\n",
        "\n",
        "        # Use GeoText to extract place names\n",
        "        places = GeoText(summary)\n",
        "        spatial_data.append(places.cities)\n",
        "\n",
        "    print(\"Spatiotemporal data extracted.\")\n",
        "    return temporal_data, spatial_data\n",
        "\n",
        "# Example usage\n",
        "temporal_data, spatial_data = extract_spatiotemporal_data()\n",
        "print(f\"Temporal Data: {temporal_data}\")\n",
        "print(f\"Spatial Data: {spatial_data}\")\n"
      ],
      "metadata": {
        "id": "3v00CYflrkPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lda_topic_modeling():\n",
        "    texts = [summary.split() for summary in summaries]  # Tokenize summaries\n",
        "    dictionary = corpora.Dictionary(texts)\n",
        "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "    lda_model = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=10)\n",
        "    topics = lda_model.print_topics()\n",
        "\n",
        "    print(\"LDA Topic Modeling Complete.\")\n",
        "    for topic in topics:\n",
        "        print(topic)\n",
        "    return topics\n",
        "\n",
        "# Example usage\n",
        "topics = lda_topic_modeling()\n"
      ],
      "metadata": {
        "id": "nwKws0fermSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_spatiotemporal_data():\n",
        "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    world.boundary.plot(ax=ax)\n",
        "\n",
        "    # Simulate plotting locations\n",
        "    for i, cities in enumerate(spatial_data):\n",
        "        for city in cities:\n",
        "            print(f\"Plotting {city} from article {i+1}\")\n",
        "            # In reality, you would geocode city names to plot on the map\n",
        "\n",
        "    plt.title(\"Spatiotemporal Data (Locations of Alzheimer's News)\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_lda_topics():\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar([\"Topic 1\", \"Topic 2\", \"Topic 3\"], [5, 10, 7])  # Simulate topic counts\n",
        "    plt.title(\"LDA Topic Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_spatiotemporal_data()\n",
        "plot_lda_topics()\n"
      ],
      "metadata": {
        "id": "4u0F4CwirorX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}